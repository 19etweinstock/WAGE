2022-01-10 1143
LR    = 1
bitsW = 8  # bit width of weights
bitsA = 8 # bit width of activations
bitsG = 15  # bit width of gradients
bitsE = 15 # bit width of errors

bitsR = 15  # bit width of randomizer

loops = 1
Epoch = 5
batchSize = 50

lr_schedule = [0, 1., 20, 0.7, 35, 0.2]

loadModel = None
# loadModel = '2021-12-03 1640(MNIST 1288 8 [0, 1.0, 20, 0.7, 35, 0.2] 50 50)'

[[0, 20, 35], [1.0, 1.0, 0.7, 0.2]]
Model: "lenet5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
qa (qa)                      multiple                  0         
_________________________________________________________________
qconv2d (qconv2d)            multiple                  150       
_________________________________________________________________
maxpool (maxpool)            multiple                  0         
_________________________________________________________________
qactivation (qactivation)    multiple                  0         
_________________________________________________________________
qconv2d_1 (qconv2d)          multiple                  1200      
_________________________________________________________________
maxpool_1 (maxpool)          multiple                  0         
_________________________________________________________________
qactivation_1 (qactivation)  multiple                  0         
_________________________________________________________________
reshape (reshape)            multiple                  0         
_________________________________________________________________
qfc (qfc)                    multiple                  15360     
_________________________________________________________________
qactivation_2 (qactivation)  multiple                  0         
_________________________________________________________________
qfc_1 (qfc)                  multiple                  10080     
_________________________________________________________________
qactivation_3 (qactivation)  multiple                  0         
_________________________________________________________________
qfc_2 (qfc)                  multiple                  840       
_________________________________________________________________
qsoftmax (qsoftmax)          multiple                  0         
=================================================================
Total params: 27,630
Trainable params: 27,630
Non-trainable params: 0
_________________________________________________________________
conv/qconv2d [5, 5, 1, 6] Scale: 1.0
conv/qconv2d_1 [5, 5, 6, 8] Scale: 1.0
fc/qfc [128, 120] Scale: 1.0
fc/qfc_1 [120, 84] Scale: 1.0
fc/qfc_2 [84, 10] Scale: 1.0
CONV: 1350 FC: 26280 TOTAL: 27630
Epoch 1/5
1200/1200 [==============================] - 47s 35ms/step - loss: 45.4749 - accuracy: 0.2341 - val_loss: 219.0758 - val_accuracy: 0.3504
Epoch 2/5
1200/1200 [==============================] - 41s 34ms/step - loss: 41.5315 - accuracy: 0.3900 - val_loss: 204.0671 - val_accuracy: 0.4418
Epoch 3/5
1200/1200 [==============================] - 40s 34ms/step - loss: 39.0751 - accuracy: 0.4514 - val_loss: 192.9837 - val_accuracy: 0.4905
Epoch 4/5
1200/1200 [==============================] - 41s 34ms/step - loss: 36.4647 - accuracy: 0.4979 - val_loss: 177.4925 - val_accuracy: 0.5428
Epoch 5/5
1200/1200 [==============================] - 41s 34ms/step - loss: 34.0672 - accuracy: 0.5601 - val_loss: 167.6341 - val_accuracy: 0.5956
40/40 [==============================] - 1s 16ms/step - loss: 167.6341 - accuracy: 0.5956
235/235 [==============================] - 3s 14ms/step - loss: 169.6075 - accuracy: 0.5825
