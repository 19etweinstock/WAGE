2021-11-21 15:08:31 

import time
import tensorflow as tf

tf.compat.v1.disable_eager_execution()
tf.compat.v1.disable_v2_behavior()

bitsW = 1  # bit width of weights
bitsA = 1  # bit width of activations
bitsG = 13  # bit width of gradients
bitsE = 13 # bit width of errors

bitsR = 16  # bit width of randomizer

lr_schedule = [0,1.1]

Epoch = 100

batchSize = 128
use_batch_norm = False

dataSet = 'MNIST'  # 'MNIST','SVHN','CIFAR10', 'ILSVRC2012'

def upper(str):
    return str.upper()

batch_text = 'batch norm' if use_batch_norm else ''

Time = time.strftime('%Y-%m-%d %H%M', time.localtime())
Notes = f'{dataSet} {bitsW}{bitsA}{upper(hex(bitsG)[2:])}{upper(hex(bitsE)[2:])} {bitsR} {lr_schedule} {Epoch} {batchSize} {batch_text}'
# Notes = 'lenet5 2888'
# Notes = 'alexnet 28CC'

GPU = [0]
validNum = 0


# loadModel = None
loadModel = '../model/2021-10-25 1108(MNIST 11DD 16 [0, 1.1] 100 128 ).tf'
# saveModel = None
# saveModel = '../model/' + Time + '(' + Notes + ')' + '.tf'


lr = tf.compat.v1.Variable(initial_value=0., trainable=False, name='lr', dtype=tf.float32)
# lr_schedule = [0, 8, 200, 1,250,1./8,300,0]
# lr_schedule = [0, 32, 40, 32./8, 60, 32./64, 80, 0]
L2 = 0

lossFunc = 'SSE'
# lossFunc = tf.losses.softmax_cross_entropy
optimizer = tf.compat.v1.train.GradientDescentOptimizer(1)  # lr is controlled in Quantize.G

# shared variables, defined by other files
seed = None
sess = None
W_scale = []
eval = None

def upper(str):
    return str.upper()

W: /device:GPU:0 Conv/conv0/ [5, 5, 1, 6] Scale:4
W: /device:GPU:0 Conv/conv1/ [5, 5, 6, 8] Scale:8
W: /device:GPU:0 Fc/fc0/ [128, 120] Scale:8
W: /device:GPU:0 Fc/fc1/ [120, 84] Scale:8
W: /device:GPU:0 Fc/fc2/ [84, 10] Scale:8
CONV: 1350 FC: 26280 Total: 27630
W: /device:GPU:0 Conv_1/conv0/ [5, 5, 1, 6] Scale:4
W: /device:GPU:0 Conv_1/conv1/ [5, 5, 6, 8] Scale:8
W: /device:GPU:0 Fc_1/fc0/ [128, 120] Scale:8
W: /device:GPU:0 Fc_1/fc1/ [120, 84] Scale:8
W: /device:GPU:0 Fc_1/fc2/ [84, 10] Scale:8
Loading model from ../model/2021-10-25 1108(MNIST 11DD 16 [0, 1.1] 100 128 ).tf ... Finished Test: 0.0120 
0000000000000000000000000000
0000000000000000000000000000
0000000000111111000000000000
0000000001111111110000000000
0000000001111111111000000000
0000000011111111111100000000
0000000011110001111100000000
0000000001110001111110000000
0000000000000000011111000000
0000000000000000001111000000
0000000000000000001111000000
0000000000000000000111000000
0000000011110000000111000000
0000000111111110001111000000
0000000111111111111111000000
0000001111111111111111000000
0000001111111111111111000000
0000001111111111111111000000
0000001111111111111111100000
0000001111111111111111110000
0000000111111111111111110000
0000000011111111000111110000
0000000000000000000000000000
0000000000000000000000000000
0000000000000000000000000000
0000000000000000000000000000
0000000000000000000000000000
0000000000000000000000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
255255125525512551255255
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
1255111125525511
255025510125502551
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0000000000
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
