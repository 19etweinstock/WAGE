2021-11-28 1516
LR    = 1
bitsW = 1  # bit width of weights
bitsA = 2 # bit width of activations
bitsG = 8  # bit width of gradients
bitsE = 8 # bit width of errors

bitsR = 8  # bit width of randomizer

Epoch = 90
batchSize = 48

lr_schedule = [0, 1., 70, 0.7]

[[0, 70], [1.0, 1.0, 0.7]]
Model: "lenet5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
qa (qa)                      multiple                  0         
_________________________________________________________________
qconv2d (qconv2d)            multiple                  150       
_________________________________________________________________
maxpool (maxpool)            multiple                  0         
_________________________________________________________________
qactivation (qactivation)    multiple                  0         
_________________________________________________________________
qconv2d_1 (qconv2d)          multiple                  1200      
_________________________________________________________________
maxpool_1 (maxpool)          multiple                  0         
_________________________________________________________________
qactivation_1 (qactivation)  multiple                  0         
_________________________________________________________________
reshape (reshape)            multiple                  0         
_________________________________________________________________
qfc (qfc)                    multiple                  15360     
_________________________________________________________________
qactivation_2 (qactivation)  multiple                  0         
_________________________________________________________________
qfc_1 (qfc)                  multiple                  10080     
_________________________________________________________________
qactivation_3 (qactivation)  multiple                  0         
_________________________________________________________________
qfc_2 (qfc)                  multiple                  840       
_________________________________________________________________
qsoftmax (qsoftmax)          multiple                  0         
=================================================================
Total params: 27,630
Trainable params: 27,630
Non-trainable params: 0
_________________________________________________________________
Epoch 1/90
1250/1250 [==============================] - 12s 8ms/step - loss: 0.0730 - accuracy: 0.4336
Epoch 2/90
1250/1250 [==============================] - 12s 9ms/step - loss: 0.0448 - accuracy: 0.6971
Epoch 3/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0326 - accuracy: 0.7904
Epoch 4/90
1250/1250 [==============================] - 12s 9ms/step - loss: 0.0268 - accuracy: 0.8310
Epoch 5/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0235 - accuracy: 0.8515
Epoch 6/90
1250/1250 [==============================] - 12s 9ms/step - loss: 0.0205 - accuracy: 0.8732
Epoch 7/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0193 - accuracy: 0.8789
Epoch 8/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0175 - accuracy: 0.8899
Epoch 9/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0160 - accuracy: 0.9005
Epoch 10/90
1250/1250 [==============================] - 12s 9ms/step - loss: 0.0151 - accuracy: 0.9052
Epoch 11/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0143 - accuracy: 0.9111
Epoch 12/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0135 - accuracy: 0.9149
Epoch 13/90
1250/1250 [==============================] - 12s 10ms/step - loss: 0.0133 - accuracy: 0.9168
Epoch 14/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0124 - accuracy: 0.9214
Epoch 15/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0122 - accuracy: 0.9228
Epoch 16/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0120 - accuracy: 0.9239
Epoch 17/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0118 - accuracy: 0.9256
Epoch 18/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0109 - accuracy: 0.9318
Epoch 19/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0109 - accuracy: 0.9319
Epoch 20/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0102 - accuracy: 0.9357
Epoch 21/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0104 - accuracy: 0.9340
Epoch 22/90
1250/1250 [==============================] - 11s 8ms/step - loss: 0.0106 - accuracy: 0.9330
Epoch 23/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0102 - accuracy: 0.9348
Epoch 24/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0106 - accuracy: 0.9327
Epoch 25/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0100 - accuracy: 0.9362
Epoch 26/90
1250/1250 [==============================] - 11s 8ms/step - loss: 0.0098 - accuracy: 0.9377
Epoch 27/90
1250/1250 [==============================] - 11s 8ms/step - loss: 0.0100 - accuracy: 0.9363
Epoch 28/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0098 - accuracy: 0.9377
Epoch 29/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0097 - accuracy: 0.9384
Epoch 30/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0093 - accuracy: 0.9409
Epoch 31/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0090 - accuracy: 0.9431
Epoch 32/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0093 - accuracy: 0.9416
Epoch 33/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0091 - accuracy: 0.9421
Epoch 34/90
1250/1250 [==============================] - 11s 8ms/step - loss: 0.0093 - accuracy: 0.9406
Epoch 35/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0092 - accuracy: 0.9408
Epoch 36/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0096 - accuracy: 0.9394
Epoch 37/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0092 - accuracy: 0.9406
Epoch 38/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0089 - accuracy: 0.9430
Epoch 39/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0087 - accuracy: 0.9444
Epoch 40/90
1250/1250 [==============================] - 11s 9ms/step - loss: 0.0090 - accuracy: 0.9430
Epoch 41/90
1250/1250 [==============================] - 10s 8ms/step - loss: 0.0087 - accuracy: 0.9446
Epoch 42/90
1250/1250 [==============================] - 11s 8ms/step - loss: 0.0088 - accuracy: 0.9441
Epoch 43/90
1250/1250 [==============================] - 12s 9ms/step - loss: 0.0086 - accuracy: 0.9445
Epoch 44/90
1250/1250 [==============================] - 12s 10ms/step - loss: 0.0084 - accuracy: 0.9457
Epoch 45/90
1250/1250 [==============================] - 12s 10ms/step - loss: 0.0085 - accuracy: 0.9452
Epoch 46/90
 997/1250 [======================>.......] - ETA: 2s - loss: nan - accuracy: 0.9442   Batch 996: Invalid loss, terminating training
1250/1250 [==============================] - 9s 7ms/step - loss: nan - accuracy: 0.9442
313/313 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0980
1875/1875 [==============================] - 7s 4ms/step - loss: nan - accuracy: 0.0987
